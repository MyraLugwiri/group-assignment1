{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MyraLugwiri/group-assignment1/blob/main/MachineLearning_GroupAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metal Surface Defects"
      ],
      "metadata": {
        "id": "hm2cwttsveVX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Sw6wvugoKW"
      },
      "source": [
        "This dataset was downloaded from NEU Metal Surface Defects Database which contains six kinds of typical surface defects of the hot-rolled steel strip are collected, i.e., rolled-in scale (RS), patches (Pa), crazing (Cr), pitted surface (PS), inclusion (In) and scratches (Sc). The database includes 1,800 grayscale images: 300 samples each of six different kinds of typical surface defects."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset was selected because it focuses on"
      ],
      "metadata": {
        "id": "tbs5JOxTGCt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Source Url = https://www.kaggle.com/datasets/fantacher/neu-metal-surface-defects-data"
      ],
      "metadata": {
        "id": "TFpdB9TPxxLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCaQRgjPmz75",
        "outputId": "5ea53404-c734-46b9-e8be-55c161ee8a7a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dSu1Kki1gJS",
        "outputId": "2cae9173-4783-455b-8fde-c5a242a6c131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzhJmquK9JM7"
      },
      "outputs": [],
      "source": [
        "# importing the necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXrBtRc4UiJ8",
        "outputId": "0b60ab88-e1b7-42cf-f5de-024056e9f995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "Qn8hYyc7vY2K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoMDnpXPFFNL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# load the dataset\n",
        "train_path = '/content/drive/MyDrive/Machine_Learning/assignments/GroupAssignment/NEU Metal Surface Defects Data/train/'\n",
        "test_path = '/content/drive/MyDrive/Machine_Learning/assignments/GroupAssignment/NEU Metal Surface Defects Data/test/'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SGPj3Lr-ycf",
        "outputId": "4737cf32-913a-4573-cbdd-be26ff00081e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scratches\n",
            "Crazing\n",
            "Rolled\n",
            "Pitted\n",
            "Inclusion\n",
            "Patches\n"
          ]
        }
      ],
      "source": [
        "defect_classes = os.listdir(test_path)\n",
        "for i, defect_type in enumerate(defect_classes) :\n",
        "    defect_path = os.path.join(test_path , defect_type)\n",
        "    label = defect_type\n",
        "    print(defect_type)\n",
        "    # for image_file  in os.listdir(defect_path):\n",
        "    #   print(image_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fkq1OChBovuZ"
      },
      "outputs": [],
      "source": [
        "# the preprocessing pipeline for training data\n",
        "def preprocess_data(data_classes, file_size):\n",
        "  \"\"\"\n",
        "  preprocesses the data and returns the train data and\n",
        "  the associated labels\n",
        "\n",
        "  \"\"\"\n",
        "  train_data = []\n",
        "  data_labels = []\n",
        "  # Travesing the data file paths to access\n",
        "  for defect_type in data_classes:\n",
        "    defect_path = os.path.join(train_path, defect_type)\n",
        "    label = defect_type\n",
        "\n",
        "    for image_file  in os.listdir(defect_path):\n",
        "      img_path = os.path.join(defect_path, image_file)\n",
        "      the_img = image.load_img(img_path, target_size=file_size) # loading the images into PIL format and convert the images from BMP to RGB\n",
        "      the_img_array = image.img_to_array(the_img)\n",
        "      the_img_array = np.expand_dims(the_img_array, axis=0)\n",
        "      the_img_array = preprocess_input(the_img_array)\n",
        "      the_img_array = the_img_array / 255.0\n",
        "\n",
        "      # appending the preprocessed images to the list\n",
        "      train_data.append(the_img_array)\n",
        "      # appending the labels of the data to the list\n",
        "      data_labels.append(label)\n",
        "\n",
        "  return np.vstack(train_data), np.array(data_labels)\n",
        "file_size = (224, 224) # 224 because VGG16 deals with images that are of the size 224\n",
        "train_data_path = os.listdir(train_path)\n",
        "X_train, Y_train = preprocess_data(train_data_path, file_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLL-9NLA9Nvp"
      },
      "outputs": [],
      "source": [
        "# preprocessing pipeline for test data\n",
        "def preprocess_test_data(test_data_path, file_size):\n",
        "  \"\"\"\n",
        "  preprocesses the data and returns the test data and\n",
        "  the associated labels\n",
        "\n",
        "  \"\"\"\n",
        "  test_data = []\n",
        "  test_data_labels = []\n",
        "  # Travesing the data file paths to access\n",
        "  for defect_type in test_data_path:\n",
        "    defect_path = os.path.join(test_path, defect_type)\n",
        "    label = defect_type\n",
        "\n",
        "    for image_file  in os.listdir(defect_path):\n",
        "\n",
        "      img_path = os.path.join(defect_path, image_file)\n",
        "      the_img = image.load_img(img_path, target_size=file_size) # loading the images into PIL format and convert the images from BMP to RGB\n",
        "      test_array = image.img_to_array(the_img)\n",
        "      test_array = np.expand_dims(test_array, axis=0)\n",
        "      test_array = preprocess_input(test_array)\n",
        "      test_array = test_array / 255.0\n",
        "\n",
        "      # appending the preprocessed images to the list\n",
        "      test_data.append(test_array)\n",
        "      # appending the labels of the data to the list\n",
        "      test_data_labels.append(label)\n",
        "\n",
        "  return np.vstack(test_data), np.array(test_data_labels)\n",
        "test_data_path = os.listdir(test_path)\n",
        "X_test, Y_test = preprocess_test_data(test_data_path, file_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0yOD_HgIdgr"
      },
      "outputs": [],
      "source": [
        "# Encoding the test labels\n",
        "labelling = LabelEncoder()\n",
        "# Y_test =  Y_test.reshape(-1,  1)\n",
        "labelling.fit(Y_test)\n",
        "Y_test = labelling.fit_transform(Y_test)\n",
        "# Y_train  = Y_train.reshape(-1, 1)\n",
        "labelling.fit(Y_train)\n",
        "Y_train = labelling.fit_transform(Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extraction"
      ],
      "metadata": {
        "id": "KZh0kXVcvSVC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXXPiWZhLj7F",
        "outputId": "97910b20-5225-4b06-dc99-eef72b34a3d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#loading the VGG16 Model\n",
        "VGG_model= VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# ensuring the VGG16 layers are untrainable\n",
        "for layer in VGG_model.layers:\n",
        "  layer.trainable = False\n",
        "# checking if the trainable layers are 0\n",
        "VGG_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwYRb_TQv_3",
        "outputId": "c4a130fa-d532-44de-8a7f-ba15f26b8ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1032s 20s/step\n"
          ]
        }
      ],
      "source": [
        "# Extracting features for X_train\n",
        "extract_features = VGG_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlv32gkuZD4w"
      },
      "outputs": [],
      "source": [
        "# reshaping the x_train features extracted from VGG16\n",
        "features = extract_features.reshape(extract_features.shape[0], -1)\n",
        "# new_X_train = extract_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H73uSX3vecng",
        "outputId": "7fb94524-6975-409e-9d22-558710b0a968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 46s 13s/step\n"
          ]
        }
      ],
      "source": [
        "# extracting features for X_test\n",
        "xtest_extract_features = VGG_model.predict(X_test)\n",
        "x_test_features = xtest_extract_features.reshape(xtest_extract_features.shape[0], -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing out Classification Model\n",
        "> 4 classification models will be tested to identify the best performing one which will then be saved to be used later"
      ],
      "metadata": {
        "id": "qDQ83ioEx-9z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUqIjKizV7-u"
      },
      "source": [
        "The following machine learning classifiers will be tested to find the best classifier model:\n",
        "\n",
        "\n",
        "*   Support Vector Machine\n",
        "*   Random Forest Classifier\n",
        "*   Naive Bayes(GaussianNB)\n",
        "*   Logistic Classifier\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0WPNTVaUWo8",
        "outputId": "b867e0ef-0472-45c7-93ee-2bab123f4ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================\n",
            "RandomForestClassifier\n",
            "****Results****\n",
            "Accuracy Score: 100.0000\n",
            "The prediction is: ['Scratches' 'Scratches' 'Scratches' 'Scratches' 'Scratches' 'Scratches'\n",
            " 'Scratches' 'Scratches' 'Scratches' 'Scratches' 'Scratches' 'Scratches'\n",
            " 'Crazing' 'Crazing' 'Crazing' 'Crazing' 'Crazing' 'Crazing' 'Crazing'\n",
            " 'Crazing' 'Crazing' 'Crazing' 'Crazing' 'Crazing' 'Rolled' 'Rolled'\n",
            " 'Rolled' 'Rolled' 'Rolled' 'Rolled' 'Rolled' 'Rolled' 'Rolled' 'Rolled'\n",
            " 'Rolled' 'Rolled' 'Pitted' 'Pitted' 'Pitted' 'Pitted' 'Pitted' 'Pitted'\n",
            " 'Pitted' 'Pitted' 'Pitted' 'Pitted' 'Pitted' 'Pitted' 'Inclusion'\n",
            " 'Inclusion' 'Inclusion' 'Inclusion' 'Inclusion' 'Inclusion' 'Inclusion'\n",
            " 'Inclusion' 'Inclusion' 'Inclusion' 'Inclusion' 'Inclusion' 'Patches'\n",
            " 'Patches' 'Patches' 'Patches' 'Patches' 'Patches' 'Patches' 'Patches'\n",
            " 'Patches' 'Patches' 'Patches' 'Patches']\n"
          ]
        }
      ],
      "source": [
        "# importing all the necessary classifiers\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# creating a list of the models\n",
        "# models = [GaussianNB(), RandomForestClassifier(), LogisticRegression(max_iter=1000), SVC(probability=True)]\n",
        "models = [RandomForestClassifier()]\n",
        "\n",
        "# defining a for loop that will loop through the models to train and calculate accuracy and loss\n",
        "column_labels = ['classifier', 'Accuracy']\n",
        "loss_calculated = pd.DataFrame(columns=column_labels)\n",
        "\n",
        "for clf in models:\n",
        "  name = clf.__class__.__name__\n",
        "  clf.fit(features, Y_train)\n",
        "\n",
        "  print('='*30)\n",
        "  print(name)\n",
        "  print('****Results****')\n",
        "  predictions = clf.predict(x_test_features)\n",
        "  accuracy_s = accuracy_score(Y_test, predictions)\n",
        "  print('Accuracy Score: {:.4f}'.format(accuracy_s*100))\n",
        "  predictions = labelling.inverse_transform(predictions)\n",
        "\n",
        "  calculated_metrics = pd.DataFrame([[name, accuracy_s*100]], columns=column_labels)\n",
        "  loss_calculated = pd.concat([loss_calculated, calculated_metrics], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selected model is RandomForestClassifier because it allows the calculations of the probabilities of the presence of any of\n",
        "the 6 defects present in an image"
      ],
      "metadata": {
        "id": "XRkXmw5HZZhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing joblib so that we can save the trained LogisticRegression Model\n",
        "import joblib\n",
        "joblib.dump(clf, 'rf_classifier.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1lkyrwdBlqW",
        "outputId": "e2570643-bd48-491f-ad61-213239c7df33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rf_classifier.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the labelEncoder\n",
        "joblib.dump(labelling, 'label_encoder.sav')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPd8kJFoON6b",
        "outputId": "eaff9a16-bcec-4bd2-8aa4-2716288f5dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.sav']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}